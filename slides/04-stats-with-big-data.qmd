---
title: "Doing statistics with big data"
format:
  revealjs:
    incremental: true
    theme: theme.scss
    transition: fade
    background-transition: fade
    highlight-style: a11y
code-link: true
execute:
  echo: true
  freeze: auto
---

# Statistics with Big Data

- The curse of dimensionality.
- The challenges of null hypothesis statistical testing.
- Visualization as a solution.
- Statistical solutions.
  - Resampling.
  - The Jackknife.
  - The Bootstrap.

# Big data

Data can be "big" in two different ways:

- Many rows in the table (large $n$).
- Many columns in the table (large $p$).
- Both of these present statistical challenges.
- A lot of attention has been put on large $n$ as a solution to Reproducibility challenges.

---

![](./images/witten_pvalues.png)

# What's wrong with NHST?

1. $H_0$ is wrong by definition
2. Rejection of the null hypothesis provides very little useful information
3. Type II errors are usually unquantified/unquantifiable.
4. Dichotomous with fundamentally arbitrary threshold.
5. Hard to use unless you restrict yourself to linear models.

---

![](./images/loftus_anova_fallacy.png)


# The Bayesian objection

- $H_0$ is rejected when.
  - $p(data | H_0) < 0.05$.
- But inference is often.
  - $p(H_0 | data) is small$.
- Which may or may not be true depending on the prior of $H_0$.
- Making $\alpha = 0.05$ even more arbitrary.

# What should we do?

- Plot the data.
- Use confidence intervals.
  - If you are using 'mixed' factorial designs, use ["within subject CIs"](https://link.springer.com/content/pdf/10.3758/BF03210951.pdf)
- Use meta analysis.
- Use an explicit model.
- Or when pressed approximate your model with "planned comparisons".

# Plotting your data



# Computing to the rescue

# Resampling methods

- Jackknife
- Cross-validation
- Permutation testing
- Bootstrapping

# The Jackknife

- Originally invented by statistician Maurice Quenouille in the 40's.
- Championed by Tukey, who also named it for its versatility and utility.
- The mechanics:
- Consider the statistic $\theta(X)$ calculated for data set $X$
- Let the sample size of the data be $X$ be $n$
- For i in 1...$n$
  - Remove the $i^{th}$ observation
  - Calculate $\theta_i = \theta(X_{-i})$ and store the value
- The jacknife estimate of is:
  - $\hat{\theta} = \frac{1}{n} \sum_{i}{\theta_i}$
- The estimate of the standard error $SE(S)$ is:
  - $SE_\theta = \sqrt{ \frac{n-1}{n} \sum_{i}{ (\hat{\theta} - \theta_i) ^2 }} $

# The jackknife

- The bias of the jackknife is smaller than the bias of $\theta$ (why?)
- Can also be used to estimate the bias of $\theta$:
  - $\hat{B} =  \hat{\theta} - \theta$

# Demo

# Some limitations

- Assumes data is IID
- Assumes that $\theta$ is $ \sim \mathcal{N}(\mu,\,\sigma^{2}) $
- Can fail badly with non-smooth estimators (e.g., median)
- We'll talk about cross-validation next week.
- And we may or may not come back to permutations later on.

# The bootstrap

Invented by Bradley Efron
- See [interview](https://youtu.be/0tA3x64nCGY?si=u_9syHVAkwlcea9V) for the back-story.
- Very general in its application
- Consider a statistic $\theta(X)$
- For i in $1...b$
  - Sample $n$ samples _with replacement_: $X_b$
  - In the pseudo-sample, calculate $\theta(X_b)$ and store the value
- Standard error is the sample standard deviation of $\theta$:
  - $\sqrt(\frac{1}{n-1} \sum_i{(\theta - \bar{\theta})^2})$
- Bias can be estimated as:
  - $\theta{X} - \bar{theta}$ (why?)
- The 95% confidence interval is in the interval between 2.5 and 97.5.

# Why is the bootstrap so effective?

- Alleviates distributional assumptions required with other methods.
- Flexible to the statistic that is being interrogated
- Allows interrogating sampling procedures
  - For example, sample with and without stratification and compare SE.
- Supports model fitting.
- And other complex procedures.
- Efron argues that this is the natural procedure Fisher et al. would have preferred in the 20's if they had computers.

# When Efron talks about computers

::: {.fragment}

He's talking about this:

![](./images/computers_in_1983.png)

:::

# Demo

# A few pitfalls of the bootstrap

Based on ["What Teachers Should Know About the Bootstrap: Resampling in the Undergraduate Statistics Curriculum"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4784504/)
by Tim Hesterberg.

# A few pitfalls

- Estimates of SE tend to bias downward in small samples.
  - By a factor of $\sqrt\frac{n-1}{n}$
- $b$ is a meta-parameter that needs to be determined
  - Efron originally claimed that $b=1,000$ should suffice
  - Hesterberg says at least 15k is required to have a 95% of being within 10% of ground truth p-values.
- Comparing distributions by comparing their 95% CI.
  - Should compare the distribution of sampled differences instead!
- In modeling: bootstrapping observations rather than bootstrapping the residuals
  - Residuals are preferable when considering a designed experiment with fixed levels of an IV.

# Building on the bootstrap

- Ensemble methods:
  - [Bagging (bootstrap aggregation)](https://link.springer.com/article/10.1007/BF00058655)
  - [Random forests](https://link.springer.com/article/10.1023/A:1010933404324)

# The curse of dimensionality

What about large $p$

- There be dragons


# Data is sparser in higher dimensions


# The distance between points increases rapidly

# When $p$ > $n$ multi-colinearity exists

# The false positive rate increases

# Machine learning to the rescue?

- Next time, we'll look at some methods that are designed to deal with the curse of dimensionality
- And may also help with some of the conceptual issues mentioned above.